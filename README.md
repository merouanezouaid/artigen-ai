# artigen-ai


This project uses Visual Language Models (VLM) to create culturally rich, professional marketing descriptions for Moroccan artisanal products. By analyzing images and retrieving relevant cultural information, the system supports Moroccan artisans by highlighting the cultural significance and craftsmanship of their products, boosting their economic prospects and preserving Moroccan heritage.

[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/WT3LQdcC63k/1.jpg)](https://www.youtube.com/watch?v=WT3LQdcC63k)


## Table of Contents

- [GenAI Challenge Path](#genai-challenge-path)
- [Project Description](#project-description)
- [Source Code](#source-code)
- [Trained Models](#trained-models)
- [Demo](#demo)
- [Evaluation Protocol and Benchmarks](#evaluation-protocol-and-benchmarks)
- [Installation](#installation)
- [Usage](#usage)
- [how it works](#how-it-works)
- [Contributing](#contributing)
- [License](#license)

## Usage

1. Retrieve an image of a Moroccan artisanal product.
2. Use the provided scripts to analyze the image and generate a marketing description.

## Contributing

We welcome contributions! Please follow these steps to contribute:

1. Fork the repository.
2. Create a new branch (`git checkout -b feature-branch`).
3. Commit your changes (`git commit -am 'Add new feature'`).
4. Push to the branch (`git push origin feature-branch`).
5. Create a new Pull Request.

## how it works

![image](https://github.com/merouanezouaid/artigen-ai/assets/65385551/10bec7a0-4a7c-4ec8-8612-94d436b58a02)


## Source Code

Link or description of the source code and notebooks used in the project.

## Trained Models

### LLaVA Model
We utilized the LLaVA (Language and Vision for Art) model, pretrained on a large corpus of art-related text and images, to enhance the cultural richness of our generated marketing descriptions.

### SAM Model
The SAM (Style Aggregated Multi-modal) model, trained on a diverse range of images and associated text, was employed to ensure the stylistic coherence and relevance of our generated descriptions.

### CLIP Model
The CLIP (Contrastive Language-Image Pretraining) model, pretrained on a massive dataset of paired images and text from the internet, played a crucial role in understanding the semantic context of images and texts, facilitating the generation of culturally relevant descriptions for Moroccan artisanal products.

## Presentation
https://docs.google.com/presentation/d/17mMKR9yVwZaIAApt6LGJooZlElwbOPb9GJf_JYcaiKI/edit?usp=sharing

## Installation
Requirement.txt

Instructions on how to set up your project. For example:

```bash
git clone https://github.com/yourusername/artigen-ai.git
cd artigen
# any other setup commands
